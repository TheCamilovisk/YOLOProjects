{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Computer Vision is a fields of computer science that focuses on enabling artificial systems to extract information from images and its variants (e.g.: video sequences, views from multiple cameras, multi-dimensional data from a 3D scanner, medical scanning devices, etc.). It makes use of algorithmic models that allow a computer to \"teach\" itself the context of visual data, learning the patterns that distinguish an image from another. Computational vision is rapidly gaining popularity for automated AI vision inspection, remote monitoring, and automation.\n",
    "\n",
    "Computer Vision has become the backbone of numerous practical applications that significantly impact our daily lives and companies across industries, from retail to security, healthcare, construction, automotive, manufacturing, logistics, and agriculture.\n",
    "\n",
    "In this scenario, one of the most groundbreaking approaches for Computer Vision is the **You Only Look Once** (YOLO) models family."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development History\n",
    "\n",
    "The first version of YOLO(You Look Only Once) was conceived by Joseph Redmon at al. in their 2015 [paper](https://arxiv.org/abs/1506.02640), and represented a groundbreaking approach in Computer Vision, particularly in object *detection tasks.* At the, time the conventional object detection frameworks (e.g.: RCNN) relied on a two-step approach: for a given image, one model is responsible for extraction of regions of objects, and a second model is responsible for classification and refinement of localization of objects. YOLOv1 (how the first version became known) challenged this convention by proposing a single neural network that predictions bounding boxes and class probabilities directly from full images in one evaluation. The approach significantly increased the speed of detection, making real-time object detection feasible.\n",
    "\n",
    "![RCNN pipeline](imgs/rcnn-pipeline.png)\n",
    "*RCNN's multi-stage detection. Credits: RCNN original [paper](https://arxiv.org/abs/1311.2524).*\n",
    "\n",
    "![YOLOv1 pipeline](imgs/yolov1-pipeline.png)\n",
    "*YOLOv1 unified detection. Credits: YOLOv1 original [paper](https://arxiv.org/abs/1506.02640).*\n",
    "\n",
    "Following the initial release, the YOLO architecture underwent several iterations and improvements, leading to version like YOLOv2 ([YOLO9000](https://arxiv.org/abs/1612.08242)), [YOLOv3](https://arxiv.org/abs/1804.02767), and further, each introducing enhancements in speed, accuracy, and the ability to detect smaller objects. [YOLOv4](https://arxiv.org/abs/2004.10934), introduced by Alexey Bochkovskiy, focused on optimizing the speed, accuracy trade-off, making it highly efficient without specialized hardware.\n",
    "\n",
    "The [Ultralytics](https://www.ultralytics.com/) team contributed significantly to the YOLO legacy with their [YOLOv5](https://docs.ultralytics.com/yolov5/) model, which brought improvements in terms of simplicity, speed, and performance. They continued this trend with the development of [YOLOv6](https://arxiv.org/abs/2209.02976) and [YOLOv8](https://docs.ultralytics.com/), which incorporates advanced features and improving upon the accuracy and efficiency of its predecessors.\n",
    "\n",
    "YOLOv8 also supports a full range of vision AI tasks, including detection, segmentation, pose estimation, tracking and classification. This versatility allows users to leverage YOLOv8's capabilities across diverse application and domains.\n",
    "\n",
    "Currently, [YOLO-NAS](https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md) and [YOLOv9](https://arxiv.org/abs/2402.13616) were conceived with remarkable improvements in efficiency, accuracy and adaptability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Pose Estimation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
